%\documentclass{ncc}
%\documentclass{article}
\documentclass{scrartcl}

\usepackage{amsmath,amssymb,amsfonts} % Typical maths resource packages
\usepackage{graphics}                 % Packages to allow inclusion of graphics
\usepackage{color}                    % For creating coloured text and background
\usepackage{hyperref}                 % For creating hyperlinks in
                                % cross references 
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian,english]{babel}

\begin{document}
\label{Chapter 1}
\section {Вводная}
\subsection* {Supervised Learnig} - where the ``right (correct)
answers'' for
each example of data is given. \\
Usually we have one of two:\\
{\bf Regression:} predict continuous valued output \\
{\bf Classification:} assign discrete valued output (0, 1 etc) \\

\subsection* {Unsupervied Learning} - finding structure in ``blind''
set of
data. \\
{\bf Clustering} algorithms  \\
Example: {\bf Coctail Party Problem} (разделение записей на двух
микрофонах от двух источниках и восстановление сигналов от каждого
источника
индивидуально). \\

\label{Chapter 2}
\section {Linear Regression with One Variable}

\subsection {Model Representation}
Notation: \\
{\bf m} =  Number of training examples \\
{\bf x}'s = ``input'' values / features \\
{\bf y}'s = ``output''variable / ``target'' variable \\
{\bf (x, y)} = one single training example \\
{\bf $(x^{(i)}, y^{(i)})$} = $i^{th}$ training example \\

Обычный алгоритм: берем Training Set, скармливаем его Learning
Algorithm. Оный строит ф-ю h (иначе hypothesis), которая по входному
значению $x$ строит Estimation. Иначе говоря, \\
h maps from x's to y's: \\
$h_\theta(x)=\theta_0 + \theta_1x$; shorthnd: h(x) \\
- т.е. полагаем что ф-я линейная \\
Другие названия:
\begin{itemize}
\item Linear regression with one variable (x)
\item Univariate linear regression
\end{itemize}
\subsection {Cost Function}
\label{2-2}
Идея - минимизировать \[ J(\theta_0, \theta_1) = \frac{1}{2m}
\sum_{i=1}^m\left( h_\theta (x^{(i)}) - y^{(i)} \right)^2
\]
Оная $J(\theta_0, \theta_1)$ и называется Cost Funcion, она же Squared
Error Function

\subsection {Gradient Descent}
\label {2-5}
Задача: имея функцию $J(\theta_0, \theta_1)$, заполучить ее
${\min \atop \theta_0, \theta_1} J(\theta_0, \theta_1)$ \\
Outline:
\begin {itemize}
\item Start with some $\theta_0, \theta_1$
\item Keep changing $\theta_0, \theta_1$ to reduce J($\theta_0,
  \theta_1$) until we hopefully end up at a minimum
\end{itemize}
Работает также для бОльшего количества параметров ( $\theta_0,
\theta_1,..., \theta_n$)
\subsubsection {Gradient descent algorithm}
repeat until convergence \{ \\
$\theta_j := \theta_j - {\alpha} \underbrace{ \frac {\delta}{\delta
    \theta_j} J(\theta_0,
  \theta_1)}_{derivative}$ (for j=0 and j=1) \\
\}, where: \\
$\alpha$ - learning rate \\
$\frac {\delta}{\delta \theta_j} J(\theta_0, \theta_1)$ - derivative
(производная, точнее, частная производная)

\subparagraph {Correct: Simultaneous upgrade}

temp0 := $\theta_0 - \alpha \frac {\delta}{\delta \theta_0}
J(\theta_0,
\theta_1)$ \\
temp1 := $\theta_1 - \alpha \frac {\delta}{\delta \theta_1}
J(\theta_0,
\theta_1)$ \\
$\theta_0$ := temp0 \\
$\theta_1$ := temp1 \\

\subsection {Gradient Descent Algorithm For Linear Regression }
\label {2-7}
После подстановок - получаем частные производные:
\[ \frac {\delta}{\delta \theta_j} J(\theta_0, \theta_1) = \frac
{\delta}{\delta \theta_j} \frac{1}{2m} \sum\limits_{i=1}^m\left(
  h_\theta (x^{(i)}) - y^{(i)} \right)^2 = \frac {\delta}{\delta
  \theta_j} \frac{1}{2m} \sum\limits_{i=1}^m\left(\theta_0 + \theta_1
  x^{(i)} - y^{(i)} \right)^2
\] \\
Тогда:
\[
\theta_0 : \frac {\delta}{\delta \theta_0} J(\theta_0, \theta_1) =
\frac{1}{m} \sum\limits_{i=1}^m\left(h_\theta (x^{(i)}) - y^{(i)}
\right) \]
\[
\theta_1 : \frac {\delta}{\delta \theta_1} J(\theta_0, \theta_1) =
\frac{1}{m} \sum\limits_{i=1}^m\left(h_\theta (x^{(i)}) - y^{(i)}
\right) * x^{(i)}
\]
Тогда алгоритм будет: \\
repeat until convergence \{ \\
\
\[\theta_0 := \theta_0 - {\alpha} \frac{1}{m}
\sum\limits_{i=1}^m\left(h_\theta (x^{(i)}) - y^{(i)} \right) \]
\[\theta_1 := \theta_1 - {\alpha} \frac{1}{m}
\sum\limits_{i=1}^m\left(h_\theta (x^{(i)}) - y^{(i)} \right) *
x^{(i)} \] \} Утверждает, что Cost Function для Linear Regression
всегда является ``bow shaped'', или ``Convex function'' - т.е. не
имеет локальных минимумов; единственный минимум - глобальный.

Дальше, он называет сей процесс ``Batch'' Gradient Descent - т.к. Each
step of gradient descent uses all the training examples.

\subsection {Extensions}
\label {2-8}
1. Существует прямой (не - итерационный) метод обсчета $\theta_0,
\theta_1$ \\
2. БОльшее количество параметров (features): $y = F(x_1, x_2, ...,
x_n)$

\label{Chapter 3}
\section {Linear Algebra Review}
Ничего интересного, обозначения:
\[
\left( \begin{array}{cc}
    1402 & 191 \\
    1371 & 821 \\ 949 & 1437 \\ 147 & 1448 \\
  \end{array} \right) = \mathbb{R}^{4\times2}
\]
Identity Matrix - единичная матрица вроде $\left( I
  = \begin{array}{cc}
    1 & 0 \\ 0 & 1 \\
  \end{array}
\right)$

Свойства: $A I = I A = A$ Обычно умножение матриц некомутативно, но
ассоциативно: $A B \neq B A$, но $(A B) C = A (B C)$

Inverse matrix - обратная матрица Transpose matrix - транспонированная
матрица

\label{Chapter 4}
\section {Linear Regression with Multiple Variables}
Notation: \\
\begin{itemize}
\item {m} = number of examples (size of training set)
\item {n} = number of features
\item{$x^{(i)}$} = input (features) of $i^{th}$ training example
  (vecotr of size n)
\item {$x_j^{(i)}$} = value of feature j in $i^{th}$ training example
\end{itemize}
Hypothesis: \\
\[
h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3 + ...
\theta_nx_n
\]
For convenience in notatiojn , define $x_0=1$. $(x_0^{(i)}=1)$:
Feature vector (values for a single feature) is of dimention n+1:
\[
x = \left[ \begin{array}{c} x_0 \\ x_1 \\ x_2 \\ \vdots \\ x_n
  \end{array} \right] \in \mathbf{R^{n+1}}
\]
The same story (n+1 dimentional vector) - for parameters:
\[
\theta = \left[ \begin{array}{c} \theta_0 \\ \theta_1 \\ \theta_2 \\
    \vdots \\ \theta_n
  \end{array} \right] \in \mathbf{R^{n+1}}
\]
(another n+1 dimentional vector) Then hypotesis can be written as:
\[
h_\theta(x) = \theta_0x_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3 +
... \theta_nx_n = \\ \theta^TX
\]
where: $\theta^T = [\theta_0 \theta_1 ... \theta_n]$ - so-called {\bf
  raw vector}. \\

This form is also called {\bf Multivariate linear regression }.

\subsection {Gradient Descent for Multiple Variables}
Cost function:
\[
J(\theta_0, \theta_1, ..., \theta_n) = \frac{1}{2m}
\sum\limits_{i=1}^m\left(h_\theta(x^{(i)}) - y^{(i)} \right)^2
\]
Gradient descent: \\
Repeat \{
\[ \theta_j := \theta_j - \alpha \frac
{\delta}{\delta\theta_j}J(\theta) \\
= \theta_j - \alpha \frac{1}{m}
\sum\limits_{i=1}^m\left(h_\theta(x^{(i)}) - y^{(i)}
\right)x_j^{(i)} \]
\} - simultaneously update for every j = 0,1,...n \\
for j = 0, the formula is the same as of Single-Variable Descent (as
$x_0 = 1$)
\label {4-3}
\subsection {Gradient Descent in practice}
Предлагается масштабировать features так, чтобы избегать ``вытянутых''
контуров на $\theta_1(\theta_2)$ диаграммах, т.к. на оных вытянутых
диаграммах процесс сходится плохо. Сие называется

\subsubsection{ Fature Scaling} 
- get every feature into approximately a $-1 \leq x_i \leq 1$ range.
\subsubsection {Mean normalization}
- replace $x_i$ with $\frac{x_i - \mu_i}{S_i}$ to make features have
approximately zero mean (do not apply to $x_0 = 1$):
\begin{itemize}
\item{$\mu_i$} - mean value
\item{$S_i$} - the range (max - min) or standard deviation (would be
  fine too)
\end{itemize}
Example:
\begin{equation*}
  \begin{split}
    x_1 = \frac{size-1000}{2000} \\
    x_2 = \frac{\#bedrooms-2}{5} \\
    -0.5 \leq x_1 \leq 0.5, -0.5 \leq x_2 \leq 0.5
  \end{split}
\end{equation*}

\subsection {Gradient Descent in Practice - Learning Rate}
\label {4-4}
Gradient descent works correctly if $J(\theta)$ decrease after every
iteration. Usually convergence is declared if $J(\theta)$ decreases by
less then some constant (i.e. $10^-{3}$) in one iteration.

If $J(\theta)$ increases (or scillates up and down) - this
usuallymeans that learning rate $\alpha$ is too big (but convergence
becomes slower).

So it is recommended to try \[ ..., 0.001,0.003, 0.01, 0.03, 0.1, 0.3,
1, ...
\]
 
\subsection{Features and Polynomial Regression}
\label{4-5}
\subsubsection{Polynomil Regression}
In polynomial regression formulas like $h_\theta(x)=\theta_0 +
\theta_qx + \theta_2x^2 + \theta^3x_3$ we can re-write the expression
as $h_\theta(x) = \theta_0 + \theta_qx_1 + \theta_2x_2 + \theta_3x_3$
where \begin{itemize}
\item{$x_1=x$}
\item{$x_2=x^2$}
\item{$x_1=x^3$}
\end{itemize}
and use the mechanics of the ``normal''linear regression. In addition,
it is usually a better idea to use some sort of ``inside'' information
- in order to choose the ``right'' set of feature. Such selection
process can also be automated.

\subsection {Normal Equation}
\label{4-6}
To solve the $\theta$ analytically. For 1-D features we can use
derivatives: $\frac{d}{d\theta}J(\theta) = 0$, solve it for $\theta$.
But if $\theta \in \mathbb{R}^{n+1}$, we need to solve \[
\frac{\delta}{\delta \theta_j}J(\theta) = \frac{\delta}{\delta
  \theta_j} \left( \frac{1}{2m}
  \sum\limits_{i=1}^m\big(h_\theta(x^{(i)}) - y^{(i)}\big)^2\right) =
0
\] for every j

The idea is: pack the training set into matrix $X^{m \times (n + 1)}$
(so-called design matrix) for features (n features + ones for $x_0$)
and m - dimentional vector y for results. Then:
\[ \theta = \mathbf{\left( X^TX \right)^{-1}X^T}y \] values in
$\theta$ will minimize the cost function. Feature scaling in this case
is NOT actual.

Octave: \emph{ pinv(X'*X)*X'*y }

\paragraph {Pro (versus Gradient Descent)} No need to choose $\alpha$,
don't need to iterate.

\paragraph {Contra} Gradient Descent works well with large $n$, while
calcualtion $n \times n$ matrix for large n could be painful.

\subsection {Normal Equasion Noninvertability}
Idea: what if $\mathbf{X^TX}$ is non-invertible (singular)?
Causes:\begin{itemize}
\item Redundant features (linearly dependent). \\
  E.g. $x_1$ = size in $feet^2$, $x_2$ = size in $m^2$
\item Too many features ($e.g. m \leq n$). \\
  Delete some features or use regularization.

\end{itemize}

In Octave, \emph{pinv(X'*X)*X'*y} will end with some meaningful result
- this is different from ``just'' \emph{inv} function (see Octave doc
for difference between the ``normal'' inversion inv and ``pseudo'' -
inversion pinv functions).

\section {Octave Tutorial}
\label {Chapter 5}
Add ``;'' to make a command (not output it immediately)\\
Commands can be comma - chained Commands / operators:\begin{itemize}
\item {PS1('>> ');} set up the command prompt
\item {help command} prints help on command
\item {\verb!~=!} works as ``not equal'' logical operator
\item {constants}: pi,
\item {output} \verb!disp(sprintf('2 decimals: %0.2f', a))!
\item {switch default output format}: format long / format short
\end{itemize}
\subsubsection {matrix}
\begin{verbatim}
A = [1 2; 3 4;
> 5 6]

>> V = [1 2 3]
\end{verbatim}
Automated init:
\begin{verbatim}
>>v = 1:0.1:2 % creates vector with 11 values: from 1.0 step 0.1 to 2.0
>>v = 1:6 % creates vector [1..6]
>> ones(2, 3) % generates 2 * 3 matrix filled with 1
>> w = zeros(1,3) % generates vector of "o"
>> rand(3,3) % generates matrix, inits with random (normal
distribution values in 0..1 range)
>> randn(1, 3) % generates matrix, inits with random (Gaussian
distribution with mean = 0 and sigma = 1)
>> eye(6) % identity matrix 6 * 6
\end{verbatim}
\verb!hist(w)! builds a histogram for given vector w

\subsection {Moving data around}
\label{5-2}
\begin{verbatim}
>> size (A) % returns dimentions of matrix A
>> size (A, 1) % returns the value for first dimention of A (rows)
>> size (A, 2) % returns the value for second dimention of A (columns)
>> lingth(v) % returns lenght of vector. For matrix - returns the
% longer dimention of matrix
>> pwd, cd, ls,   % CO
>> load filename.ext / load('filename.ext') % loads text files with
% data into relevant variable
>> who % lists variables in memory
>> whos % more detailed 'who'
>> clear <variable name> % deletes variable from memory. If called
% without parameter - clears all variables
>> v = V(1:10) % get the first 10 elements of V
>> save hello.mat v; % saves vector v to file hello.mat (binary
% format) to save in human - readable format, use -ascii option

>> A(3, 2) % returns element of matrix A
>> A(2, :) % fetch everything in the second row. Works for columns as
% well; can be used for assigning
>> A([1 3], :) % get everything from rows 1 and 3
>> A = [A , [100; 101; 102]]; % appends the column vector to the
% matrix (notice ';' as delimiter for elements in column)
>> A(:) % put all elements of A into a single vector
>> C = [A B] % concatenate matrices into a new one (horisontally).
% Same is [A, B] (comma instead of space)
>> C = [A;B] % concatenate matrices vertically 
\end{verbatim}

\subsection{Computing on Data}
\label{5-3}
\begin{verbatim}
>> A*C % matrix multiplication
>> A .* B % element-wise operations: each element of A is being
% multiplied by corresponding element of B
>> A .^ 2 % element-wise power
>> 1 ./ v % element-wise reciprocal of v (every element of a new
% vector is 1 / corresponding element of v)
>> log(v), exp(v), abs(a), -v % element-wise log, exp, abs, negative
>> v + ones(length(v), 1) % adds 1 to every element of v (one can do
% it simpler v + 1)
>> A' % A transposed
>> max(v) % maximum element of v. For matrix - give "per-row" maximum
% by default. Trick to calculate the maximum element of matrix:
% max(A(:))
>> [val, ind] = max(v) % assigns val to max value, ind, to the index
% of max element from v
>> v < 3 % element-wise comparing (builds matrix with 0/1 per element)
>> find (v < 3) % returns vector with elements satisfying the
% condition
>> magic(3) % returns "magic square"
>> sum(A), prod(A) % sum and product of all elements of matrix. By
% default - "per-column" (1st dimention - just like sum(A,1). Per-row
% will be calculated by sum(A(:))
>>sum(sum(A.*eye(9))) % trick to calculate the sum of all elements on
% the matrix diagonal. For other diagonal: sum(sum(A.*flipud(eye(9))))
>> floor(A), ceil(A) % rounding all elements
>> rand(3) % create rundom matrix 3x3
>> max(a, b) % generate matrix with values = element-wise max of both.
% Also exist "per-row" and "per-column" form
>> pinv(A) %"pseudo-inverse matrix 
\end{verbatim}

\subsection{Plotting Data}
\label{5-4}
\begin{itemize}
\item{plot(t, y)} - plot graph with points $t_i, y_i$ from vectors
\item{hold on} - plot 1st graph, ``hold on'', plot another one
\item{xlabel('time'), ylabel('value')} - set labelx for x and y
\item{legend('sin', 'cos'), title('my plot')} - legend and title
\item{print -dpng 'myPlot.png'} - save to file
\item{close} - remove plot
\item{figure(1);plot(t,y1);figure(2);plot(t,y2);} - builds two plots
  on different widows
\item{subplot(1, 2, 1)} - divide plot a 1x2 grid, access first element
\item{axis([0.5 1 -1 1])} - set x- and y- ranges
\item{clf;} - clear
\item{imagesc(A)} - draw image based on goven matrix A
\item{imagesc(A), colorbar, colormap gray} - as before, add colorbar
  legend, make legend grayscale
\end{itemize}

\subsection{Control Statement}
\label{5-5}
\subsubsection{Control Statements}
\begin{verbatim}
for i=1:10
 v(i) = 2^i;
end;
% or, having a vector like indices=1:10; we can do similar:
for i=indices,
 disp(i);
end;
% _break_ and _continue_ apply
================
i = 1;
while i <= 5,
 v(i) = 100;
 i = i + 1;
end;
========
if i == 6, break;
=======
if i == 6, disp('oops');
elseif v(i) == 2, disp('aah');
else disp('grgrg');
end;
\end{verbatim}
\subsubsection{functions}
Create file named <function-name>.m (text). Example:
\begin{verbatim}
function y = squareThisNumber(x)

y = x^2;
\end{verbatim}
Then use it in Octave:
\begin{verbatim}
>> cd <folder with file>
>> squareThisNumber(5)
===== or use addpath ('some\path\to\function') - see search path idea
\end{verbatim}
Multiple-variable returning functions
\begin{verbatim}
function [y1, y2] = squareAndCubeThisNumber(x)

y1 = x^2;
y2 = x^3;
\end{verbatim}
Variant: $J(\theta)$
\begin{verbatim}
function j = costFunctionJ(X, y, theta)
% X - "design matrix" with training examples y - class labesls

m = size(X, 1)  % number of training examples
predictions = X*theta % predictionsof hypothesis on all m examples
sqrError = (predicitons-y).^2; %squared error (element-wise)

J = 1/(2*m) * sum(sqeErrors);
\end{verbatim}
\subsection{Vectorization}
\label{5-6}
Idea: instead of using cycles (loops) over data matrices or vectors,
use matrix(vector) multiplication operations.

\label {Chapter 6}
\section {Logistic Regression}
\subsection{Classification}
Idea is to separate the input into cathegories like Spam/Ham,
Malignant / Benign Tumor etc. Sepatation: \begin{itemize}
\item {Two-class} (``binary class'') classification $y \in \{0, 1\}$
\item {Multi-class} classification $y \in \{0, 1, ... n\}$
\end{itemize}
Idea: to use Linear Regression with $h_\theta(x) = \theta^T x$ and
threachold which checks: \begin{itemize}
\item{if $h_\theta(x) \geq 0.5$} predict 1
\item{if $h_\theta(x) < 0.5$} predict 0
\end{itemize}
Problem emerges when the training set is not lineary separated, so
``if paramater greater ... then ...'' does not work. In addition, h
can be > 1 or < 0. As such , we need something like \[ Logistic
Regression: 0 \leq h_\theta(x) \leq 1
\]
It is named ``regression'' for historical reason, but this is actually
a classification algorithm.

\subsection{Hypothesis Representation}
We use Linear Regression Model ($h_\theta(x) = \theta^Tx$ ) with
so-called {\bf Sigmoid function} or {\bf Logistic function} : \[
h_\theta(x) = g(\theta^Tx), where \]
\[g(z) = frac{1}{1 + e^{-z}}\] so
\begin{equation*}
  h_\theta(x) = \frac{1}{1 + e^{-\theta^Tx}}
\end{equation*}
(see function graph for this)
\subsubsection{Interpretaion}
$h_\theta(x) = $ estimated probability that y=1 on input x
\begin{equation*}
  \textrm{Example: if }  x = \left[ \begin{array}{c} x_0 \\
      x_1  \end{array} \right] = \left[ \begin{array}{c} 1 \\
      tumorSize  \end{array} \right]
\end{equation*}
\begin{equation*} h_\theta(x) = 0.7 \end{equation*} - then patient has
70\% chance of tumor being malignant. Or: $ h_\theta(x) = \frac{1}{1 +
  e^{-\theta^Tx}}$ - ``probability that y = 1, given
x, parametrized by $\theta$'' \\
As y = 0 or 1, then:
\[P( y = 0 | x;\theta) + P(y=1|x;\theta) = 1\]
\[P( y = 0 | x;\theta) = 1 - P(y=1|x;\theta)\]

\subsection{Decision Boundary}
Suppose predict ``y = 1'' if $h_\theta(x) \geq 0.5$ \\
and ``y = 0'' if $h_\theta(x) < 0.5$ \\

as $g(z) \geq 0.5 \ when \ Z \geq 0 \Rightarrow h_\theta(x) =
g(\theta^Tx) \geq 0.5 \ whenever \ \theta^Tx \geq 0$
\label {page 10 from pdf}

Decision boundary - a line that separates regions with different
predictions. It is a property of a hypothesis (not training set!).

\subsection{Cost Function}
\label{sec:6-4}
Training set: $\{(x^{(1)},y^{(1)}), (x^{(2)},y^{(2)}), \dots ,
(x^{(m)},y^{(m)})\}$ of m examples; x is a vector of
$\mathbf{R^{n+1}}$, where $x_0 = 1, y \in \{0, 1\}$. We're choosing
the parameters $\theta$ to minimise
\[ \textrm{hypothesis:} h_\theta(x) = \frac{1}{1 + e^{-\theta^T x}} \]
\[ \textrm{Modify Linear regression:} J(\theta) = \frac{1}{m}
\sum\limits_{i=1}^m Cost (h_\theta(x^{(i)}, y^{(i)}) \]
\[ \textrm{where } Cost (h_\theta(x^{(i)}, y^{(i)}) =
\frac{1}{2}(h_\theta(x^{(i)}) - y^{(i)})^2 \]

Logistic cost function is ``non-convex'', which means it can have a
number of local minimums, as a result we can not work with derivative.
Instead, we use iteration method based on \[ \textrm{hypothesis:}
Cost(h_\theta(x), y) = \left\{ \begin{array}
    {rr} -log(h_\theta(x)) & \textrm{if y = 1} \\
    -log(1- h_\theta(x)) & \textrm{if y = 0}
  \end{array} \right. \]

\paragraph{for y=1:}
Cost = 0 if y = 1, $h_\theta(x) = 1$
but as $h_\theta(x) \to 0 \Rightarrow \textrm{Cost } \to \infty $ \\
That captures intuition that if $h_\theta(x) = 0$, predict
$P(y=1|x;\theta) = 0$, but for y=1 we'll penaltize algorithm by a very
large cost.

\paragraph{for y=0:}
Cost = 0 for $h_\theta(x) = 0$, penalty for $h_\theta(x) = 1$

Together it gives convex function suitable for iterative processing.

\label{6-5}


\label {Chapter 7}
\section {Regularization}

\label {Chapter 8}
\section {Neural Networks: Representation}


% \end {description}
\end{document}
